{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scientific Computing - Practice sessions  : Audio command recognition by DTW and classification\n",
    "\n",
    "**Group name:**\n",
    "\n",
    "**Names :**\n",
    "\n",
    "**Surnames :**\n",
    "\n",
    "The Practice sessions will permit testing the dynamic programming algorithm (DTW) seen in Exercise session (TD) and then implement an audio recognition system for isolated words (constituting orders for drones).\n",
    "\n",
    "\n",
    "These sessions are divided into 3 parts: \n",
    "- Part I: DTW and application of the TD\n",
    "- Part II: Audio control word recognition system\n",
    "- Part III: Comparison of dynamic programming with a classification method after data pre-processing by PCA\n",
    "\n",
    "For **parts II and III**, you will test the audio recognition system on two sets of voices that will serve as a learning base (references) and a test base (sounds to be recognized) respectively. The list of the 13 drone commands are: *Landing, Takeoff, Takeoff, Advance, Right turn, Backward, Left turn, Right, Flip, Left, Stop, Higher, Lower and State of Emergency.*\n",
    "\n",
    "To do this, you must per group of 2 students (number of students **MANDATORY**):\n",
    "1. **Propose a study** that you will detail on a report.\n",
    "For example, *influence male voices VS female voices, compare your own voices to the database, test the impact of different background noises on recognition...*];\n",
    "2. Create, according to the objective of your study, your own learning base and test base from the proposed corpus and the voices and sounds you have recorded   [*audio parameters: 16 KHz, mono, 16 bits, *.wav format**];\n",
    "3. Test the DTW and a classification method with pre-processing by PCA;\n",
    "4. Evaluate the results; \n",
    "5. Write a pdf report presenting the study, the results by the 2 methods and your comments and conclusions on your study (Max. length: 8 pages).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy import array, zeros, full, argmin, inf, ndim\n",
    "import scipy\n",
    "import sklearn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Implementation of the dynamic programming algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a function in DTW python that implements the calculation and display of the cost matrix defined in TD. \n",
    "\n",
    "2. In order to easily adapt the cost calculation according to the nature of the data (and therefore the distances used), write a function for each distance (Euclidean, letters, sounds) that will appear as a parameter of the DTW function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application to exercises \n",
    "\n",
    "1. Test your programs on the exercises seen in TD. \n",
    "\n",
    "2. Modify the local constraints, i.e. the weights according to the directions. \n",
    "\n",
    "3. Add the consideration of global constraints, i. e. non-calculation when the boxes are too far from the diagonal (see exercise TD DNA sequence). From which position do global constraints not change the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Audio control word recognition system\n",
    "\n",
    "On the shared space, you will find audio recordings of command words for a quadricopter drone composed of several male french speakers (noted M01...M13) and female french speakers (F01...F05).\n",
    "\n",
    "You can thus divide all the data into learning bases that will serve as references and test bases to evaluate recognition by dynamic programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code allow you to transform the audio file into a matrix of parameters called MFCC (Mel Frequency Cepstral Coefficient) using the *librosa* python library. These settings are used to extract the best possible frequency voice content from the audio signal.\n",
    "\n",
    "The output matrix is composed of as many column vectors as analysis frames. The number of lines corresponds to the size of the representative vector: here 12.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Audio file upload:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(audio_file, offset=30, duration=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MFCC extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=1024, htk=True, n_mfcc=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Application of DTW**\n",
    "\n",
    "1. Carry out a study that you will detail on a report (for example, *influence male voices VS female voices, compare your own voice with the database, test the impact of different background noises on recognition...*) and create your own learning database and test database from the corpus and the voices and noises you have recorded. \n",
    "\n",
    "2. Apply DTW to your corpora.\n",
    "\n",
    "**Settings for audio recordings of your personal voices:**\n",
    "\n",
    "16 KHz, mono, 16 bits, *.wav* format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assessment of recognition**\n",
    "\n",
    "1. Calculate the system confusion matrix (in line with the references and in column the system outputs). \n",
    "You can use the *confusion_matrix* function of the *sklearn* library.\n",
    "\n",
    "\n",
    "2. Calculate the recognition score: number of well recognized files on number of tested files. \n",
    "\n",
    "*Verification:*\n",
    "- if you use the M01 reference and test file, you must get no errors.\n",
    "- if you use as M01 reference file and M02 test file, you must get two errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Comparison of dynamic programming with a classification method after data pre-processing\n",
    "\n",
    "In this section, we will compare the results of DTW with those of a data classification method: the k-nearest neighbors (k-nn).\n",
    "\n",
    "We will use the functions to calculate the PCA and k-nn via the python library *scikit-learn*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA preprocessing\n",
    "\n",
    "To test a classification method, the size of the MFCCs must first be reduced:\n",
    "\n",
    "1. From all the records in the learning database, perform a Principal Component Analysis (PCA) using the *PCA* function of the *scikit-learn* library and then project the test data into this new database. \n",
    "\n",
    "*Note:* You can also implement the PCA by\n",
    "extracting the 3 eigenvectors, noted $X_1$, $X_2$, $X_3$, associated with the 3 largest eigenvalues of the\n",
    "variance-covariance $\\Sigma_{App}$ (by the functions *np.cov* and *np.linalg.eig*). These eigenvectors will constitute the new benchmark P. Then project the data from the learning and test database into this new database by multiplying each vector by the database $P =[X_1X_2X_3]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification by k nearest neighbors\n",
    "\n",
    "In artificial intelligence, the k nearest neighbor method (*k-nn*) is a supervised method. In this context, there is a learning database of \"label-data\" pairs. To estimate the output associated with a new input $x$, the $k$ nearest neighbor  method consists of taking into account (in the same way) the $k$ learning samples whose input is closest to the new input $x$, according to a distance to be defined. The associated algorithm and an example are given below.\n",
    "\n",
    "<img src=\"files/knn.jpg\" width=\"700\" height=\"500\" >\n",
    "\n",
    "<img src=\"files/kppv.png\" width=\"300\" height=\"300\" >\n",
    "\n",
    "**Example of classification by k-nn.** The test sample (green circle) must be classified either in the first\n",
    "class of blue squares, or in the second class of red triangles. \n",
    "If k = 3 (full circle), it is assigned to the second class because there are 2 triangles and only 1 square inside the inner circle. \n",
    "If k = 5 (dotted circle), it is assigned to the first class (3 squares against 2 triangles inside the outer circle)\n",
    "\n",
    "\n",
    "1. Using the *KNeighborsClassifier* function of the *sklearn.neighbors library*, perform a classification by k-nn on the learning and test basis you have predefined (take $k=1$).\n",
    "\n",
    "2. Evaluate the k-nn method by calculating the confusion matrix and the recognition rate.\n",
    "\n",
    "3. Change the value of $k$ for k-nn. Do you improve recognition scores?\n",
    "\n",
    "4. Compare your results with those of DTW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
